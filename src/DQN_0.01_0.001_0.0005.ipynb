{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5526,
     "status": "ok",
     "timestamp": 1624403011807,
     "user": {
      "displayName": "Adarsh Gouda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiLxey_F4S6zXQQzRixQirKM2ByMsjtktDTWY5hdw=s64",
      "userId": "10706865863009541265"
     },
     "user_tz": 360
    },
    "id": "mWJAoAVDkEZV",
    "outputId": "9d8f7137-15c6-4a26-89e7-b307d7cda3b0"
   },
   "outputs": [],
   "source": [
    "#!pip3 install box2d-py\n",
    "#!pip3 install gym[Box_2D]\n",
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import random\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time as time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable this code to disable the GPU execution\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable all GPUS\n",
    "  tf.config.set_visible_devices([], 'GPU')\n",
    "  visible_devices = tf.config.get_visible_devices()\n",
    "  for device in visible_devices:\n",
    "    assert device.device_type != 'GPU'\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1624403019276,
     "user": {
      "displayName": "Adarsh Gouda",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiLxey_F4S6zXQQzRixQirKM2ByMsjtktDTWY5hdw=s64",
      "userId": "10706865863009541265"
     },
     "user_tz": 360
    },
    "id": "skFSI-YokZl8"
   },
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    \n",
    "    def __init__(self, game, retrain = False, epsilon=1, epsilon_decay = 0.995, \n",
    "                 epsilon_min = 0.1, batch_size = 64, discount_factor=0.99, episodes=1000, alpha = 0.01, lr=0.001):\n",
    "        \n",
    "        self.ep = epsilon\n",
    "        self.ep_decay = epsilon_decay\n",
    "        self.ep_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = discount_factor\n",
    "        self.episodes = episodes\n",
    "        self.game = game\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.retrain = retrain\n",
    "        \n",
    "        self.frames = []\n",
    "        \n",
    "        seed = 983827\n",
    "        mem = 1000000\n",
    "\n",
    "        self.csv_filename = \"ep0p01_0p001_0p0005.csv\"\n",
    "        self.model_filename = \"ep0p01_0p001_0p0005.h5\"\n",
    "\n",
    "        \n",
    "        self.env = gym.make(game)\n",
    "        self.env.seed(seed)\n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        self.nS = self.env.observation_space.shape[0]\n",
    "        self.nA = self.env.action_space.n\n",
    "        \n",
    "        print(\"state size is: \",self.nS)\n",
    "        print(\"action size is: \", self.nA)\n",
    "       \n",
    "        \n",
    "        self.memory = deque(maxlen=1000000)  #Creating a container to replay meomory, double linked list.\n",
    "\n",
    "        if self.retrain == False:\n",
    "          self.Q_model = self.setup_dnn()\n",
    "          self.Q_hat_model = self.setup_dnn()\n",
    "          print(\"NEW MODEL CREATED!\")\n",
    "        \n",
    "        else:\n",
    "\n",
    "          self.Q_model = tf.keras.models.load_model(self.model_filename)\n",
    "          self.Q_hat_model = tf.keras.models.load_model(self.model_filename)\n",
    "          print(\"MODEL LOADED!\")\n",
    "          self.Q_model.summary()\n",
    "\n",
    "\n",
    "        self.counter = 0\n",
    "        self.update_freq = 4\n",
    "\n",
    "        \n",
    "        self.df_ddqn = pd.DataFrame(columns = [\"Episode\", \"Epsilon\", \"Reward\", \"Mean_Reward\", \"Time\"])\n",
    "        \n",
    "    def setup_dnn(self):\n",
    "        \n",
    "        input_ = tf.keras.layers.Input(shape = (self.nS))\n",
    "        \n",
    "        hidden1_ = tf.keras.layers.Dense(64, activation = \"relu\")(input_)\n",
    "        hidden2_ = tf.keras.layers.Dense(64, activation = \"relu\")(hidden1_)\n",
    "        output_ = tf.keras.layers.Dense(self.nA)(hidden2_)\n",
    "        \n",
    "        model_ = tf.keras.Model(inputs = [input_], outputs = [output_])\n",
    "        opt_ = tf.keras.optimizers.Adam(self.lr)\n",
    "        model_.compile(optimizer = opt_, loss = \"mse\")\n",
    "        \n",
    "        return model_\n",
    "    \n",
    "    def action(self, state, epsilon):\n",
    "        \n",
    "        if np.random.rand() < epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            Q_values = self.Q_model.predict(state) #Greedy policy w.r.t Q\n",
    "            \n",
    "        return np.argmax(Q_values[0])\n",
    "    \n",
    "    \n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        \n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    \n",
    "    def weights_update(self):\n",
    "        Q_w = self.Q_model.get_weights()\n",
    "        Q_hat_w = self.Q_hat_model.get_weights()\n",
    "        \n",
    "        for w in range(len(Q_hat_w)):\n",
    "            Q_hat_w[w] = self.alpha * Q_w[w] + (1-self.alpha) * Q_hat_w[w]\n",
    "        \n",
    "        self.Q_hat_model.set_weights(Q_hat_weights)\n",
    "        \n",
    "\n",
    "    '''\n",
    "        \n",
    "    def learn(self):\n",
    "        \n",
    "        if self.ep > self.ep_min:\n",
    "            self.ep *= self.ep_decay\n",
    "        \n",
    "        samples = random.choices(self.memory, k = self.batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, done in samples:\n",
    "            target = reward\n",
    "            \n",
    "            if not done:\n",
    "                target = reward + self.gamma*np.max(self.model.predict(next_state)[0])\n",
    "            \n",
    "            end_target = self.model.predict(state)\n",
    "            end_target[0][action] = target\n",
    "            \n",
    "            self.history = self.model.fit(state, end_target, verbose = 0)\n",
    "    '''\n",
    "    \n",
    "    def learn_batch(self):\n",
    "             \n",
    "        self.counter = (self.counter + 1) % self.update_freq\n",
    "        \n",
    "        if self.counter == 0:\n",
    "            #print(\"Learning...\")\n",
    "            if len(self.memory) < self.batch_size:\n",
    "                return\n",
    "            \n",
    "            states, end_targets = [], []\n",
    "            \n",
    "            samples = random.choices(self.memory, k = self.batch_size)\n",
    "            \n",
    "            for state, action, reward, next_state, done in samples:\n",
    "                target = reward\n",
    "            \n",
    "                if not done:\n",
    "                    target = reward + self.gamma*np.max(self.Q_hat_model.predict(next_state)[0])\n",
    "            \n",
    "                end_target = self.Q_model.predict(state)\n",
    "                end_target[0][action] = target\n",
    "                \n",
    "                states.append(state[0])\n",
    "                end_targets.append(end_target[0])\n",
    "            \n",
    "            self.Q_model.fit(np.array(states), np.array(end_targets), verbose = 0, epochs = 1)\n",
    "            \n",
    "            Q_w = self.Q_model.get_weights()\n",
    "            Q_hat_w = self.Q_hat_model.get_weights()\n",
    "        \n",
    "            for w in range(len(Q_hat_w)):\n",
    "                Q_hat_w[w] = self.alpha * Q_w[w] + (1-self.alpha) * Q_hat_w[w]\n",
    "        \n",
    "            self.Q_hat_model.set_weights(Q_hat_w)\n",
    "    \n",
    "    \n",
    "    def play(self): \n",
    "        \n",
    "        new_row = {}\n",
    "        R = []\n",
    "        R_moving = deque(maxlen=100)\n",
    "        steps = 500\n",
    "        \n",
    "        for e in range(self.episodes):\n",
    "            current_state = self.env.reset()\n",
    "            current_state = np.reshape(current_state, [1,current_state.shape[0]])\n",
    "         \n",
    "            time = 0\n",
    "            r = 0\n",
    "            \n",
    "            for s in range(steps):\n",
    "\n",
    "                action_ = self.action(current_state, self.ep)\n",
    "               \n",
    "                next_state, reward, done, info = self.env.step(action_)\n",
    "                \n",
    "                next_state = np.reshape(next_state, [1, next_state.shape[0]])\n",
    "                \n",
    "                self.store(current_state, action_, reward, next_state, done)\n",
    "                \n",
    "                r = r+reward\n",
    "                \n",
    "                #self.learn()\n",
    "                self.learn_batch()\n",
    "                \n",
    "                current_state = next_state\n",
    "                time = time+1\n",
    "                \n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            #self.learn_batch()\n",
    "            R.append(r)\n",
    "            R_moving.append(r)\n",
    "\n",
    "                    \n",
    "            new_row = {'Episode':e, 'Epsilon':self.ep, 'Reward': r, 'Mean_Reward':np.mean(R_moving), 'Time':time}\n",
    "            self.df_ddqn = self.df_ddqn.append(new_row, ignore_index = True)\n",
    "            \n",
    "            \n",
    "            if e % 5 == 0:\n",
    "              print(\"Episode: \", e, \" , Epsilon: \", self.ep, ', Reward', r,\", mean_reward: \",np.mean(R_moving) ,\", time_score: \", time, \", memory: \", len(self.memory))\n",
    "\n",
    "            if e % 100 == 0:\n",
    "\n",
    "              self.Q_model.save(self.model_filename)\n",
    "              \n",
    "\n",
    "            if self.ep > self.ep_min:\n",
    "              self.ep *= self.ep_decay\n",
    "            else:\n",
    "              self.ep = 0.01\n",
    "            \n",
    "            if np.mean(R_moving)>= 200.0:\n",
    "                print(\"BRAVO, GOAL ACHIEVED!!!\")\n",
    "                break\n",
    "\n",
    "        with open(self.csv_filename, 'a') as f:\n",
    "          self.df_ddqn.to_csv(f, header=f.tell()==0, index=False)\n",
    "             \n",
    "            \n",
    "        self.Q_model.save(self.model_filename)\n",
    "        \n",
    "        self.env.close()\n",
    "        \n",
    "        return self.df_ddqn\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8Y5T6-ukZoN",
    "outputId": "08631fbc-a90e-4a07-d724-3d4eee9fcdb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size is:  8\n",
      "action size is:  4\n",
      "NEW MODEL CREATED!\n",
      "Episode:  0  , Epsilon:  0.01 , Reward -411.22926308033425 , mean_reward:  -411.22926308033425 , time_score:  61 , memory:  61\n",
      "Episode:  5  , Epsilon:  0.01 , Reward -117.06335631448749 , mean_reward:  -282.6968358885762 , time_score:  64 , memory:  476\n",
      "Episode:  10  , Epsilon:  0.01 , Reward -647.1776840039406 , mean_reward:  -276.95112033228173 , time_score:  369 , memory:  1621\n",
      "Episode:  15  , Epsilon:  0.01 , Reward -552.5427241477502 , mean_reward:  -310.9905204480321 , time_score:  110 , memory:  2521\n",
      "Episode:  20  , Epsilon:  0.01 , Reward -237.34176335580023 , mean_reward:  -316.0751406189226 , time_score:  330 , memory:  3476\n",
      "Episode:  25  , Epsilon:  0.01 , Reward -377.55857922097124 , mean_reward:  -326.8516531362709 , time_score:  241 , memory:  4807\n",
      "Episode:  30  , Epsilon:  0.01 , Reward -349.5497255106724 , mean_reward:  -335.7563290065775 , time_score:  243 , memory:  6168\n",
      "Episode:  35  , Epsilon:  0.01 , Reward -256.60171981557136 , mean_reward:  -324.97435287458296 , time_score:  376 , memory:  8053\n",
      "Episode:  40  , Epsilon:  0.01 , Reward -446.6708642984865 , mean_reward:  -329.2058557150537 , time_score:  243 , memory:  9571\n",
      "Episode:  45  , Epsilon:  0.01 , Reward -364.49613080479753 , mean_reward:  -334.41199294442595 , time_score:  233 , memory:  10746\n",
      "Episode:  50  , Epsilon:  0.01 , Reward -431.4357593691679 , mean_reward:  -335.6856856654813 , time_score:  287 , memory:  12247\n",
      "Episode:  55  , Epsilon:  0.01 , Reward -480.83246126374377 , mean_reward:  -337.26730526999773 , time_score:  468 , memory:  14170\n",
      "Episode:  60  , Epsilon:  0.01 , Reward -99.22661159260441 , mean_reward:  -322.9619274464519 , time_score:  391 , memory:  16052\n",
      "Episode:  65  , Epsilon:  0.01 , Reward -256.5006289065646 , mean_reward:  -312.5684646375051 , time_score:  453 , memory:  18347\n",
      "Episode:  70  , Epsilon:  0.01 , Reward -393.1622518736288 , mean_reward:  -309.02656311337057 , time_score:  219 , memory:  20008\n",
      "Episode:  75  , Epsilon:  0.01 , Reward -244.5045569300982 , mean_reward:  -299.75651166963064 , time_score:  398 , memory:  22006\n",
      "Episode:  80  , Epsilon:  0.01 , Reward -118.66225603393062 , mean_reward:  -284.983307702249 , time_score:  381 , memory:  24301\n",
      "Episode:  85  , Epsilon:  0.01 , Reward 67.87195997094278 , mean_reward:  -273.1687177139809 , time_score:  500 , memory:  26196\n",
      "Episode:  90  , Epsilon:  0.01 , Reward -37.651132651837656 , mean_reward:  -260.0603568393834 , time_score:  290 , memory:  28043\n",
      "Episode:  95  , Epsilon:  0.01 , Reward -297.62196343495293 , mean_reward:  -256.0029411910322 , time_score:  289 , memory:  29707\n",
      "Episode:  100  , Epsilon:  0.01 , Reward 29.093680672867407 , mean_reward:  -243.28117788369292 , time_score:  500 , memory:  31923\n",
      "Episode:  105  , Epsilon:  0.01 , Reward -241.0530185405573 , mean_reward:  -237.40597213782183 , time_score:  397 , memory:  34287\n",
      "Episode:  110  , Epsilon:  0.01 , Reward -240.13013575660517 , mean_reward:  -228.7350103970388 , time_score:  498 , memory:  36720\n",
      "Episode:  115  , Epsilon:  0.01 , Reward -288.7424830589212 , mean_reward:  -219.80409056126328 , time_score:  145 , memory:  38393\n",
      "Episode:  120  , Epsilon:  0.01 , Reward -30.778942365705124 , mean_reward:  -205.34478078843972 , time_score:  500 , memory:  40640\n",
      "Episode:  125  , Epsilon:  0.01 , Reward -73.18836935394087 , mean_reward:  -187.51605433884703 , time_score:  500 , memory:  43140\n",
      "Episode:  130  , Epsilon:  0.01 , Reward 7.777048412715316 , mean_reward:  -171.6336071953608 , time_score:  500 , memory:  45291\n",
      "Episode:  135  , Epsilon:  0.01 , Reward -58.73678193254509 , mean_reward:  -161.55888040185337 , time_score:  500 , memory:  47675\n",
      "Episode:  140  , Epsilon:  0.01 , Reward -50.81358900349018 , mean_reward:  -145.08780011173891 , time_score:  500 , memory:  49998\n",
      "Episode:  145  , Epsilon:  0.01 , Reward -5.702597594206901 , mean_reward:  -126.27641753274376 , time_score:  500 , memory:  52423\n",
      "Episode:  150  , Epsilon:  0.01 , Reward 65.85761199970638 , mean_reward:  -112.24675984724966 , time_score:  500 , memory:  54875\n",
      "Episode:  155  , Epsilon:  0.01 , Reward -19.30709983740908 , mean_reward:  -95.28833595809725 , time_score:  500 , memory:  57375\n",
      "Episode:  160  , Epsilon:  0.01 , Reward -52.20879192602755 , mean_reward:  -89.3282547727438 , time_score:  500 , memory:  59875\n",
      "Episode:  165  , Epsilon:  0.01 , Reward -18.901056968457816 , mean_reward:  -81.47321402231064 , time_score:  500 , memory:  62375\n",
      "Episode:  170  , Epsilon:  0.01 , Reward -53.15654397386004 , mean_reward:  -69.19592300676531 , time_score:  500 , memory:  64875\n",
      "Episode:  175  , Epsilon:  0.01 , Reward -17.79531942291536 , mean_reward:  -61.78887569218267 , time_score:  500 , memory:  67375\n",
      "Episode:  180  , Epsilon:  0.01 , Reward -29.767789317033298 , mean_reward:  -59.07952251218783 , time_score:  500 , memory:  69875\n",
      "Episode:  185  , Epsilon:  0.01 , Reward -4.746593528814799 , mean_reward:  -55.49073339411442 , time_score:  500 , memory:  72375\n",
      "Episode:  190  , Epsilon:  0.01 , Reward -66.29079345219586 , mean_reward:  -56.63767568561946 , time_score:  500 , memory:  74875\n",
      "Episode:  195  , Epsilon:  0.01 , Reward -7.120878757610405 , mean_reward:  -47.84332143733162 , time_score:  500 , memory:  77375\n",
      "Episode:  200  , Epsilon:  0.01 , Reward 11.195872279542332 , mean_reward:  -46.75933427018503 , time_score:  500 , memory:  79875\n",
      "Episode:  205  , Epsilon:  0.01 , Reward -3.7160826752948948 , mean_reward:  -40.81302438647992 , time_score:  500 , memory:  82375\n",
      "Episode:  210  , Epsilon:  0.01 , Reward -49.40155227888011 , mean_reward:  -37.79082043436017 , time_score:  500 , memory:  84875\n",
      "Episode:  215  , Epsilon:  0.01 , Reward -12.311794296139677 , mean_reward:  -28.69951232305482 , time_score:  500 , memory:  87375\n",
      "Episode:  220  , Epsilon:  0.01 , Reward -31.54244972772313 , mean_reward:  -27.696798192408647 , time_score:  500 , memory:  89875\n",
      "Episode:  225  , Epsilon:  0.01 , Reward 17.82826816988102 , mean_reward:  -27.547860149502444 , time_score:  500 , memory:  92375\n",
      "Episode:  230  , Epsilon:  0.01 , Reward -33.3632262629473 , mean_reward:  -26.798254112571286 , time_score:  500 , memory:  94875\n",
      "Episode:  235  , Epsilon:  0.01 , Reward 20.54573059467153 , mean_reward:  -26.503741175121366 , time_score:  500 , memory:  97302\n",
      "Episode:  240  , Epsilon:  0.01 , Reward -11.800132889982528 , mean_reward:  -25.77668534492514 , time_score:  500 , memory:  99802\n",
      "Episode:  245  , Epsilon:  0.01 , Reward -17.487075943440495 , mean_reward:  -27.91036302059 , time_score:  500 , memory:  102065\n",
      "Episode:  250  , Epsilon:  0.01 , Reward -21.57003710847619 , mean_reward:  -26.514010542294137 , time_score:  500 , memory:  104565\n",
      "Episode:  255  , Epsilon:  0.01 , Reward -36.59566156942164 , mean_reward:  -27.64094711706878 , time_score:  500 , memory:  107065\n",
      "Episode:  260  , Epsilon:  0.01 , Reward -15.20253590594722 , mean_reward:  -28.66305358783438 , time_score:  500 , memory:  109339\n",
      "Episode:  265  , Epsilon:  0.01 , Reward -118.75774570356683 , mean_reward:  -30.87557389661788 , time_score:  300 , memory:  111493\n",
      "Episode:  270  , Epsilon:  0.01 , Reward -5.37194160665346 , mean_reward:  -32.15138647054014 , time_score:  500 , memory:  113993\n",
      "Episode:  275  , Epsilon:  0.01 , Reward -10.482375444269353 , mean_reward:  -32.5322854584381 , time_score:  500 , memory:  116493\n",
      "Episode:  280  , Epsilon:  0.01 , Reward 9.337190979018928 , mean_reward:  -32.39338025774958 , time_score:  500 , memory:  118993\n",
      "Episode:  285  , Epsilon:  0.01 , Reward -10.270143178560707 , mean_reward:  -31.974889417824016 , time_score:  500 , memory:  121493\n",
      "Episode:  290  , Epsilon:  0.01 , Reward -58.20552236398805 , mean_reward:  -30.366057657582715 , time_score:  500 , memory:  123993\n",
      "Episode:  295  , Epsilon:  0.01 , Reward -16.525256471325815 , mean_reward:  -30.864782000681274 , time_score:  500 , memory:  126493\n",
      "Episode:  300  , Epsilon:  0.01 , Reward 47.39610278609466 , mean_reward:  -29.582598256779253 , time_score:  500 , memory:  128993\n",
      "Episode:  305  , Epsilon:  0.01 , Reward -3.9286434080419133 , mean_reward:  -29.59418335509534 , time_score:  500 , memory:  131493\n",
      "Episode:  310  , Epsilon:  0.01 , Reward 27.05301658520067 , mean_reward:  -28.615147819932716 , time_score:  500 , memory:  133993\n",
      "Episode:  315  , Epsilon:  0.01 , Reward -51.295012310781736 , mean_reward:  -28.86755663861994 , time_score:  500 , memory:  136493\n",
      "Episode:  320  , Epsilon:  0.01 , Reward 46.27283997121013 , mean_reward:  -27.82209263991803 , time_score:  500 , memory:  138993\n",
      "Episode:  325  , Epsilon:  0.01 , Reward -31.245873054641113 , mean_reward:  -28.41752908179456 , time_score:  500 , memory:  141493\n",
      "Episode:  330  , Epsilon:  0.01 , Reward -150.31617457377263 , mean_reward:  -28.82286767145117 , time_score:  263 , memory:  143756\n",
      "Episode:  335  , Epsilon:  0.01 , Reward 14.335440188446363 , mean_reward:  -27.24350627753888 , time_score:  500 , memory:  146256\n",
      "Episode:  340  , Epsilon:  0.01 , Reward 19.215323238742755 , mean_reward:  -27.622619318678286 , time_score:  500 , memory:  148421\n",
      "Episode:  345  , Epsilon:  0.01 , Reward -23.151157027720892 , mean_reward:  -28.196202411839128 , time_score:  500 , memory:  150921\n",
      "Episode:  350  , Epsilon:  0.01 , Reward -69.16774475632012 , mean_reward:  -29.41905631570642 , time_score:  500 , memory:  153036\n",
      "Episode:  355  , Epsilon:  0.01 , Reward -35.00735059002548 , mean_reward:  -28.139860776655333 , time_score:  500 , memory:  155536\n",
      "Episode:  360  , Epsilon:  0.01 , Reward -125.21013998053046 , mean_reward:  -27.515223943951955 , time_score:  141 , memory:  157677\n",
      "Episode:  365  , Epsilon:  0.01 , Reward -23.147928246502044 , mean_reward:  -26.123923289886058 , time_score:  500 , memory:  159095\n",
      "Episode:  370  , Epsilon:  0.01 , Reward -26.859828034541035 , mean_reward:  -24.349378835822886 , time_score:  500 , memory:  161397\n",
      "Episode:  375  , Epsilon:  0.01 , Reward -3.9437840683421115 , mean_reward:  -25.959712437092403 , time_score:  86 , memory:  162455\n",
      "Episode:  380  , Epsilon:  0.01 , Reward -175.68991180965654 , mean_reward:  -28.9783163923754 , time_score:  108 , memory:  164563\n",
      "Episode:  385  , Epsilon:  0.01 , Reward 31.008436529557084 , mean_reward:  -29.57146191840652 , time_score:  500 , memory:  165972\n",
      "Episode:  390  , Epsilon:  0.01 , Reward 20.68285825523101 , mean_reward:  -28.642448499876664 , time_score:  500 , memory:  168472\n",
      "Episode:  395  , Epsilon:  0.01 , Reward -11.221328955695375 , mean_reward:  -27.730251054447667 , time_score:  500 , memory:  170972\n",
      "Episode:  400  , Epsilon:  0.01 , Reward 24.66143101889054 , mean_reward:  -28.776018232779702 , time_score:  162 , memory:  172355\n",
      "Episode:  405  , Epsilon:  0.01 , Reward 15.279734032304248 , mean_reward:  -29.130835279546258 , time_score:  500 , memory:  174855\n",
      "Episode:  410  , Epsilon:  0.01 , Reward -71.87805954435046 , mean_reward:  -29.18711192198931 , time_score:  187 , memory:  177042\n",
      "Episode:  415  , Epsilon:  0.01 , Reward -47.78928709990614 , mean_reward:  -30.209801729283424 , time_score:  500 , memory:  179200\n",
      "Episode:  420  , Epsilon:  0.01 , Reward -50.683533401164965 , mean_reward:  -31.585432164974055 , time_score:  500 , memory:  181270\n",
      "Episode:  425  , Epsilon:  0.01 , Reward -29.614798304674668 , mean_reward:  -31.097852651960462 , time_score:  500 , memory:  183770\n",
      "Episode:  430  , Epsilon:  0.01 , Reward -19.8244532055505 , mean_reward:  -29.710654712263374 , time_score:  500 , memory:  186270\n",
      "Episode:  435  , Epsilon:  0.01 , Reward 3.8972915575809104 , mean_reward:  -29.832391854256013 , time_score:  500 , memory:  188094\n",
      "Episode:  440  , Epsilon:  0.01 , Reward 7.2217780612859155 , mean_reward:  -31.52497472519865 , time_score:  500 , memory:  190346\n",
      "Episode:  445  , Epsilon:  0.01 , Reward -31.110014128100605 , mean_reward:  -29.679517190159576 , time_score:  500 , memory:  192846\n",
      "Episode:  450  , Epsilon:  0.01 , Reward -52.788484629035175 , mean_reward:  -27.74065502728209 , time_score:  500 , memory:  194167\n",
      "Episode:  455  , Epsilon:  0.01 , Reward -128.11981410387162 , mean_reward:  -28.42982198872807 , time_score:  378 , memory:  196545\n",
      "Episode:  460  , Epsilon:  0.01 , Reward 12.965192929513732 , mean_reward:  -27.91307131647126 , time_score:  500 , memory:  198317\n",
      "Episode:  465  , Epsilon:  0.01 , Reward -22.988713686406868 , mean_reward:  -26.83603706652867 , time_score:  158 , memory:  200437\n",
      "Episode:  470  , Epsilon:  0.01 , Reward 4.311580456390303 , mean_reward:  -26.42333886754235 , time_score:  500 , memory:  202937\n",
      "Episode:  475  , Epsilon:  0.01 , Reward -47.296087786681376 , mean_reward:  -24.658553780262665 , time_score:  500 , memory:  205078\n",
      "Episode:  480  , Epsilon:  0.01 , Reward -12.20981811866685 , mean_reward:  -21.42982298734665 , time_score:  500 , memory:  207220\n",
      "Episode:  485  , Epsilon:  0.01 , Reward -52.94748327608913 , mean_reward:  -22.821011455770908 , time_score:  500 , memory:  209468\n",
      "Episode:  490  , Epsilon:  0.01 , Reward 53.96904397856652 , mean_reward:  -23.58669607176937 , time_score:  500 , memory:  211902\n",
      "Episode:  495  , Epsilon:  0.01 , Reward 19.764544167693774 , mean_reward:  -24.64988038713902 , time_score:  500 , memory:  214095\n",
      "Episode:  500  , Epsilon:  0.01 , Reward -21.132891877001054 , mean_reward:  -26.23000666733878 , time_score:  500 , memory:  216549\n",
      "Episode:  505  , Epsilon:  0.01 , Reward 14.714368877593772 , mean_reward:  -25.76035917512424 , time_score:  500 , memory:  218768\n",
      "Episode:  510  , Epsilon:  0.01 , Reward 53.69925065594194 , mean_reward:  -26.36954432628677 , time_score:  500 , memory:  220773\n",
      "Episode:  515  , Epsilon:  0.01 , Reward 47.936747787538444 , mean_reward:  -23.57832666185056 , time_score:  500 , memory:  223273\n",
      "Episode:  520  , Epsilon:  0.01 , Reward 1.6640189428188743 , mean_reward:  -22.556676610202672 , time_score:  500 , memory:  225773\n",
      "Episode:  525  , Epsilon:  0.01 , Reward -157.81577466381313 , mean_reward:  -23.998916278452583 , time_score:  472 , memory:  228245\n",
      "Episode:  530  , Epsilon:  0.01 , Reward 4.997216479859117 , mean_reward:  -22.444679034436874 , time_score:  500 , memory:  230745\n",
      "Episode:  535  , Epsilon:  0.01 , Reward 52.09492486209113 , mean_reward:  -20.396290095268384 , time_score:  500 , memory:  233245\n",
      "Episode:  540  , Epsilon:  0.01 , Reward -2.2222603415015314 , mean_reward:  -17.539091347818058 , time_score:  500 , memory:  235745\n",
      "Episode:  545  , Epsilon:  0.01 , Reward 26.12670885350971 , mean_reward:  -17.383431295458866 , time_score:  500 , memory:  237901\n",
      "Episode:  550  , Epsilon:  0.01 , Reward 44.896971635226805 , mean_reward:  -15.162378772406814 , time_score:  500 , memory:  240084\n",
      "Episode:  555  , Epsilon:  0.01 , Reward 2.903659215008568 , mean_reward:  -12.875993075046928 , time_score:  500 , memory:  242584\n",
      "Episode:  560  , Epsilon:  0.01 , Reward -39.501915689300816 , mean_reward:  -9.684936708148335 , time_score:  500 , memory:  245084\n",
      "Episode:  565  , Epsilon:  0.01 , Reward -5.279309821778294 , mean_reward:  -8.079861187502868 , time_score:  500 , memory:  247584\n",
      "Episode:  570  , Epsilon:  0.01 , Reward 11.318248003084726 , mean_reward:  -7.146633285522053 , time_score:  500 , memory:  250084\n",
      "Episode:  575  , Epsilon:  0.01 , Reward -5.286275697172653 , mean_reward:  -5.220824595770713 , time_score:  500 , memory:  252584\n",
      "Episode:  580  , Epsilon:  0.01 , Reward 23.110398696375047 , mean_reward:  -5.766390413449696 , time_score:  500 , memory:  254726\n",
      "Episode:  585  , Epsilon:  0.01 , Reward 21.679956901068163 , mean_reward:  -2.243102822667506 , time_score:  500 , memory:  257226\n",
      "Episode:  590  , Epsilon:  0.01 , Reward 48.80768092618407 , mean_reward:  -0.3529068349625174 , time_score:  500 , memory:  259726\n",
      "Episode:  595  , Epsilon:  0.01 , Reward 5.9724475848200225 , mean_reward:  0.6443921298192614 , time_score:  500 , memory:  262226\n",
      "Episode:  600  , Epsilon:  0.01 , Reward 48.17300307279183 , mean_reward:  3.3839986227521788 , time_score:  500 , memory:  264726\n",
      "Episode:  605  , Epsilon:  0.01 , Reward 29.642949153174694 , mean_reward:  6.0569707317313055 , time_score:  500 , memory:  267226\n",
      "Episode:  610  , Epsilon:  0.01 , Reward 26.99608099946671 , mean_reward:  8.510228601621487 , time_score:  500 , memory:  269726\n",
      "Episode:  615  , Epsilon:  0.01 , Reward 1.9160172999703569 , mean_reward:  8.889669487575128 , time_score:  500 , memory:  272226\n",
      "Episode:  620  , Epsilon:  0.01 , Reward -33.02389888391499 , mean_reward:  8.094945811878866 , time_score:  500 , memory:  274351\n",
      "Episode:  625  , Epsilon:  0.01 , Reward -21.680346940156348 , mean_reward:  9.625049598045408 , time_score:  500 , memory:  276505\n",
      "Episode:  630  , Epsilon:  0.01 , Reward 9.697561364075924 , mean_reward:  9.815214786341022 , time_score:  500 , memory:  279005\n",
      "Episode:  635  , Epsilon:  0.01 , Reward -7.111788373432702 , mean_reward:  8.855992236260107 , time_score:  202 , memory:  281207\n",
      "Episode:  640  , Epsilon:  0.01 , Reward -3.4425792151670036 , mean_reward:  9.53459459161299 , time_score:  500 , memory:  283377\n",
      "Episode:  645  , Epsilon:  0.01 , Reward 28.428484488670943 , mean_reward:  12.009406059828176 , time_score:  500 , memory:  285877\n",
      "Episode:  650  , Epsilon:  0.01 , Reward 57.91475904576231 , mean_reward:  11.946614229119097 , time_score:  500 , memory:  288095\n",
      "Episode:  655  , Epsilon:  0.01 , Reward 1.6592817736075884 , mean_reward:  11.109765709989315 , time_score:  500 , memory:  290595\n",
      "Episode:  660  , Epsilon:  0.01 , Reward 15.028385135968888 , mean_reward:  11.19014319154061 , time_score:  500 , memory:  293095\n",
      "Episode:  665  , Epsilon:  0.01 , Reward 14.429803076051803 , mean_reward:  11.525700763842984 , time_score:  500 , memory:  295595\n",
      "Episode:  670  , Epsilon:  0.01 , Reward -9.036864568133034 , mean_reward:  10.080675232727293 , time_score:  500 , memory:  297804\n",
      "Episode:  675  , Epsilon:  0.01 , Reward 9.293397360994257 , mean_reward:  9.886331285873993 , time_score:  500 , memory:  300304\n",
      "Episode:  680  , Epsilon:  0.01 , Reward 16.55690210525179 , mean_reward:  10.34949716985051 , time_score:  500 , memory:  302804\n",
      "Episode:  685  , Epsilon:  0.01 , Reward 20.910104005202427 , mean_reward:  9.679717103287473 , time_score:  500 , memory:  305304\n",
      "Episode:  690  , Epsilon:  0.01 , Reward -38.68462369934054 , mean_reward:  9.685329074916323 , time_score:  500 , memory:  307804\n",
      "Episode:  695  , Epsilon:  0.01 , Reward 0.09548360877627432 , mean_reward:  10.769868096709518 , time_score:  500 , memory:  310304\n",
      "Episode:  700  , Epsilon:  0.01 , Reward 7.846457342950693 , mean_reward:  9.789080344202368 , time_score:  500 , memory:  312804\n",
      "Episode:  705  , Epsilon:  0.01 , Reward 20.533737561832407 , mean_reward:  8.75203424057959 , time_score:  500 , memory:  315304\n",
      "Episode:  710  , Epsilon:  0.01 , Reward -25.110588137159468 , mean_reward:  8.210537700660966 , time_score:  500 , memory:  317804\n",
      "Episode:  715  , Epsilon:  0.01 , Reward 14.07106356225824 , mean_reward:  9.044339314440329 , time_score:  500 , memory:  320304\n",
      "Episode:  720  , Epsilon:  0.01 , Reward 21.516934129909075 , mean_reward:  11.455128607720448 , time_score:  500 , memory:  322804\n",
      "Episode:  725  , Epsilon:  0.01 , Reward -18.09937796846066 , mean_reward:  12.377151968379257 , time_score:  500 , memory:  325304\n",
      "Episode:  730  , Epsilon:  0.01 , Reward 24.629012092368146 , mean_reward:  12.8731594468235 , time_score:  500 , memory:  327804\n",
      "Episode:  735  , Epsilon:  0.01 , Reward 39.61536534071642 , mean_reward:  13.3729928296031 , time_score:  500 , memory:  330304\n",
      "Episode:  740  , Epsilon:  0.01 , Reward 5.581241947807764 , mean_reward:  13.002721948110334 , time_score:  500 , memory:  332804\n",
      "Episode:  745  , Epsilon:  0.01 , Reward 12.280643112053031 , mean_reward:  12.281227054747676 , time_score:  500 , memory:  335304\n",
      "Episode:  750  , Epsilon:  0.01 , Reward 18.555807385042655 , mean_reward:  11.870020153723218 , time_score:  500 , memory:  337804\n",
      "Episode:  755  , Epsilon:  0.01 , Reward -16.584660261100794 , mean_reward:  12.415074035483835 , time_score:  500 , memory:  340304\n",
      "Episode:  760  , Epsilon:  0.01 , Reward 5.729808904074824 , mean_reward:  11.549897136549838 , time_score:  500 , memory:  342804\n",
      "Episode:  765  , Epsilon:  0.01 , Reward 25.074049289898014 , mean_reward:  11.452114212800764 , time_score:  500 , memory:  345304\n",
      "Episode:  770  , Epsilon:  0.01 , Reward 46.46973690232147 , mean_reward:  12.443624626141919 , time_score:  500 , memory:  347804\n",
      "Episode:  775  , Epsilon:  0.01 , Reward -157.82737397213157 , mean_reward:  9.767133781740453 , time_score:  84 , memory:  349478\n",
      "Episode:  780  , Epsilon:  0.01 , Reward 12.321566223531416 , mean_reward:  6.848462869448269 , time_score:  500 , memory:  351560\n",
      "Episode:  785  , Epsilon:  0.01 , Reward -14.51553530866947 , mean_reward:  6.02525054360316 , time_score:  104 , memory:  353343\n",
      "Episode:  790  , Epsilon:  0.01 , Reward 31.8432101454497 , mean_reward:  5.8565167493381 , time_score:  500 , memory:  355843\n",
      "Episode:  795  , Epsilon:  0.01 , Reward -93.62358819672532 , mean_reward:  4.546047873085205 , time_score:  455 , memory:  358298\n",
      "Episode:  800  , Epsilon:  0.01 , Reward -7.363513926649623 , mean_reward:  5.238702891917401 , time_score:  500 , memory:  360798\n",
      "Episode:  805  , Epsilon:  0.01 , Reward -5.609911203816594 , mean_reward:  5.178893192110763 , time_score:  500 , memory:  363298\n",
      "Episode:  810  , Epsilon:  0.01 , Reward -7.6811024503740635 , mean_reward:  5.080240205912963 , time_score:  500 , memory:  365798\n",
      "Episode:  815  , Epsilon:  0.01 , Reward 5.43074075763334 , mean_reward:  3.04063435754579 , time_score:  500 , memory:  368026\n",
      "Episode:  820  , Epsilon:  0.01 , Reward 0.03513159055494497 , mean_reward:  3.3207954395119423 , time_score:  500 , memory:  370526\n",
      "Episode:  825  , Epsilon:  0.01 , Reward 28.81401178402358 , mean_reward:  2.694627640215858 , time_score:  500 , memory:  372826\n",
      "Episode:  830  , Epsilon:  0.01 , Reward 18.514231861573528 , mean_reward:  2.3386328989960727 , time_score:  500 , memory:  375326\n",
      "Episode:  835  , Epsilon:  0.01 , Reward 20.518197943119958 , mean_reward:  2.450974533339339 , time_score:  500 , memory:  377826\n",
      "Episode:  840  , Epsilon:  0.01 , Reward -23.227744007192634 , mean_reward:  2.439697889650311 , time_score:  500 , memory:  380326\n",
      "Episode:  845  , Epsilon:  0.01 , Reward 23.251544605800454 , mean_reward:  2.6062061164369648 , time_score:  500 , memory:  382826\n",
      "Episode:  850  , Epsilon:  0.01 , Reward -15.802376068970334 , mean_reward:  2.315649046296703 , time_score:  500 , memory:  385326\n",
      "Episode:  855  , Epsilon:  0.01 , Reward 4.406864654384945 , mean_reward:  0.9667810029722265 , time_score:  500 , memory:  387522\n",
      "Episode:  860  , Epsilon:  0.01 , Reward -33.088029357993385 , mean_reward:  0.9084041837967706 , time_score:  500 , memory:  390022\n",
      "Episode:  865  , Epsilon:  0.01 , Reward 18.39810419039416 , mean_reward:  0.5719074005485154 , time_score:  500 , memory:  392522\n",
      "Episode:  870  , Epsilon:  0.01 , Reward -13.481266779761036 , mean_reward:  -0.07018535286947226 , time_score:  500 , memory:  395022\n",
      "Episode:  875  , Epsilon:  0.01 , Reward -6.36578305948741 , mean_reward:  2.679805818413834 , time_score:  500 , memory:  397522\n",
      "Episode:  880  , Epsilon:  0.01 , Reward 13.12459855496327 , mean_reward:  6.067042233080491 , time_score:  500 , memory:  400022\n",
      "Episode:  885  , Epsilon:  0.01 , Reward -0.7446384527089613 , mean_reward:  6.768624235596677 , time_score:  500 , memory:  402522\n",
      "Episode:  890  , Epsilon:  0.01 , Reward -30.79268561113749 , mean_reward:  6.676466499929436 , time_score:  500 , memory:  405022\n",
      "Episode:  895  , Epsilon:  0.01 , Reward -26.01432376430792 , mean_reward:  7.350531395481292 , time_score:  500 , memory:  407522\n",
      "Episode:  900  , Epsilon:  0.01 , Reward 24.641695364057924 , mean_reward:  7.270164152211837 , time_score:  500 , memory:  410022\n",
      "Episode:  905  , Epsilon:  0.01 , Reward 6.471493153791167 , mean_reward:  5.656554990762356 , time_score:  500 , memory:  412221\n",
      "Episode:  910  , Epsilon:  0.01 , Reward -3.961938958006434 , mean_reward:  5.265277790075555 , time_score:  500 , memory:  414721\n",
      "Episode:  915  , Epsilon:  0.01 , Reward 41.81192040967902 , mean_reward:  6.644415154512847 , time_score:  500 , memory:  417221\n",
      "Episode:  920  , Epsilon:  0.01 , Reward 13.82133986738799 , mean_reward:  6.154156994520405 , time_score:  500 , memory:  419721\n",
      "Episode:  925  , Epsilon:  0.01 , Reward 29.966428915460984 , mean_reward:  7.517131773708241 , time_score:  500 , memory:  422221\n",
      "Episode:  930  , Epsilon:  0.01 , Reward -6.613339804884591 , mean_reward:  8.058717939698985 , time_score:  500 , memory:  424721\n",
      "Episode:  935  , Epsilon:  0.01 , Reward 34.991916698464394 , mean_reward:  7.747433453384715 , time_score:  500 , memory:  427221\n",
      "Episode:  940  , Epsilon:  0.01 , Reward -30.781924902977693 , mean_reward:  5.330125620458444 , time_score:  500 , memory:  429130\n",
      "Episode:  945  , Epsilon:  0.01 , Reward 15.601195866673741 , mean_reward:  4.494489237628852 , time_score:  500 , memory:  431630\n",
      "Episode:  950  , Epsilon:  0.01 , Reward 15.442339208714046 , mean_reward:  4.897943012941406 , time_score:  500 , memory:  434130\n",
      "Episode:  955  , Epsilon:  0.01 , Reward -28.166975254593556 , mean_reward:  5.049444800612739 , time_score:  500 , memory:  436630\n",
      "Episode:  960  , Epsilon:  0.01 , Reward -51.52405262755254 , mean_reward:  3.8196714747674387 , time_score:  500 , memory:  438841\n",
      "Episode:  965  , Epsilon:  0.01 , Reward -27.92240790763341 , mean_reward:  3.2335422230885307 , time_score:  500 , memory:  441341\n",
      "Episode:  970  , Epsilon:  0.01 , Reward 16.174584214738022 , mean_reward:  3.886812083248505 , time_score:  500 , memory:  443841\n",
      "Episode:  975  , Epsilon:  0.01 , Reward 4.0048423752355635 , mean_reward:  3.5765409541069797 , time_score:  500 , memory:  446341\n",
      "Episode:  980  , Epsilon:  0.01 , Reward -14.068403120941648 , mean_reward:  3.45920196998294 , time_score:  500 , memory:  448841\n",
      "Episode:  985  , Epsilon:  0.01 , Reward 21.580943146452796 , mean_reward:  2.1109042714892015 , time_score:  500 , memory:  451341\n",
      "Episode:  990  , Epsilon:  0.01 , Reward -30.125342591372547 , mean_reward:  -3.1373513196869514 , time_score:  500 , memory:  453160\n",
      "Episode:  995  , Epsilon:  0.01 , Reward -39.842277257489535 , mean_reward:  -2.962989626807335 , time_score:  500 , memory:  455660\n",
      "Episode:  1000  , Epsilon:  0.01 , Reward -12.603866266619235 , mean_reward:  -4.080416395754705 , time_score:  500 , memory:  458160\n",
      "Episode:  1005  , Epsilon:  0.01 , Reward 2.573867793212015 , mean_reward:  -3.480717847225759 , time_score:  500 , memory:  460660\n",
      "Episode:  1010  , Epsilon:  0.01 , Reward -0.6849672791933972 , mean_reward:  -4.83916130683988 , time_score:  500 , memory:  462820\n",
      "Episode:  1015  , Epsilon:  0.01 , Reward 6.486002792195994 , mean_reward:  -6.105491850394701 , time_score:  500 , memory:  465320\n",
      "Episode:  1020  , Epsilon:  0.01 , Reward -13.922979425572796 , mean_reward:  -6.616484678647103 , time_score:  500 , memory:  467820\n",
      "Episode:  1025  , Epsilon:  0.01 , Reward -41.95078221334203 , mean_reward:  -10.327517320771124 , time_score:  500 , memory:  469981\n",
      "Episode:  1030  , Epsilon:  0.01 , Reward -53.23536377944669 , mean_reward:  -16.232694296326542 , time_score:  500 , memory:  471898\n",
      "Episode:  1035  , Epsilon:  0.01 , Reward 6.646853262997255 , mean_reward:  -16.12688237764073 , time_score:  500 , memory:  474398\n",
      "Episode:  1040  , Epsilon:  0.01 , Reward 22.646551679939442 , mean_reward:  -16.09574669099395 , time_score:  500 , memory:  476575\n",
      "Episode:  1045  , Epsilon:  0.01 , Reward 5.041979536592503 , mean_reward:  -16.543316419156632 , time_score:  500 , memory:  479075\n",
      "Episode:  1050  , Epsilon:  0.01 , Reward 18.875300065534915 , mean_reward:  -18.856572972946527 , time_score:  500 , memory:  481561\n",
      "Episode:  1055  , Epsilon:  0.01 , Reward 42.03922380947026 , mean_reward:  -16.18316455849397 , time_score:  500 , memory:  484061\n",
      "Episode:  1060  , Epsilon:  0.01 , Reward 1.417379309144889 , mean_reward:  -14.69036303010514 , time_score:  500 , memory:  486561\n",
      "Episode:  1065  , Epsilon:  0.01 , Reward -203.03029399788386 , mean_reward:  -16.47369147939113 , time_score:  179 , memory:  488740\n",
      "Episode:  1070  , Epsilon:  0.01 , Reward -20.241744631209766 , mean_reward:  -18.397828399970727 , time_score:  500 , memory:  491240\n",
      "Episode:  1075  , Epsilon:  0.01 , Reward 20.503500129919896 , mean_reward:  -20.98294308637219 , time_score:  500 , memory:  493427\n",
      "Episode:  1080  , Epsilon:  0.01 , Reward 1.7487323008983704 , mean_reward:  -21.435190308693823 , time_score:  500 , memory:  495927\n",
      "Episode:  1085  , Epsilon:  0.01 , Reward 33.88959981766031 , mean_reward:  -20.173524066095172 , time_score:  500 , memory:  498427\n",
      "Episode:  1090  , Epsilon:  0.01 , Reward 36.44042738169445 , mean_reward:  -14.463160686863668 , time_score:  500 , memory:  500927\n",
      "Episode:  1095  , Epsilon:  0.01 , Reward -138.32438307221864 , mean_reward:  -17.879805237393015 , time_score:  150 , memory:  502724\n",
      "Episode:  1100  , Epsilon:  0.01 , Reward 27.76002312441408 , mean_reward:  -15.640055673593405 , time_score:  500 , memory:  505224\n",
      "Episode:  1105  , Epsilon:  0.01 , Reward -13.829044182066482 , mean_reward:  -15.236472126813004 , time_score:  500 , memory:  507724\n",
      "Episode:  1110  , Epsilon:  0.01 , Reward -15.281554362389826 , mean_reward:  -15.129715438368155 , time_score:  500 , memory:  509892\n",
      "Episode:  1115  , Epsilon:  0.01 , Reward 48.902821724564205 , mean_reward:  -14.764916169998582 , time_score:  500 , memory:  512066\n",
      "Episode:  1120  , Epsilon:  0.01 , Reward -28.39242892019121 , mean_reward:  -21.058587641817233 , time_score:  500 , memory:  513536\n",
      "Episode:  1125  , Epsilon:  0.01 , Reward -12.904674630171833 , mean_reward:  -17.706096430408767 , time_score:  500 , memory:  516036\n",
      "Episode:  1130  , Epsilon:  0.01 , Reward -6.7224950667893015 , mean_reward:  -15.911750869020304 , time_score:  500 , memory:  517865\n",
      "Episode:  1135  , Epsilon:  0.01 , Reward 82.53755329524388 , mean_reward:  -15.137066243456276 , time_score:  500 , memory:  520365\n",
      "Episode:  1140  , Epsilon:  0.01 , Reward -192.4496370331876 , mean_reward:  -15.862038312299406 , time_score:  162 , memory:  522218\n",
      "Episode:  1145  , Epsilon:  0.01 , Reward -56.80323680659902 , mean_reward:  -20.82166936204879 , time_score:  500 , memory:  523755\n",
      "Episode:  1150  , Epsilon:  0.01 , Reward -7.343882107868031 , mean_reward:  -21.43163079000074 , time_score:  500 , memory:  525591\n",
      "Episode:  1155  , Epsilon:  0.01 , Reward 6.199645918885116 , mean_reward:  -23.250463626468385 , time_score:  500 , memory:  528091\n",
      "Episode:  1160  , Epsilon:  0.01 , Reward -32.44117883089681 , mean_reward:  -23.454070639023257 , time_score:  500 , memory:  530591\n",
      "Episode:  1165  , Epsilon:  0.01 , Reward -35.29317364543734 , mean_reward:  -23.043122756848305 , time_score:  500 , memory:  532792\n",
      "Episode:  1170  , Epsilon:  0.01 , Reward 26.717103094442063 , mean_reward:  -22.784780194546116 , time_score:  500 , memory:  534994\n",
      "Episode:  1175  , Epsilon:  0.01 , Reward 61.754866346258844 , mean_reward:  -21.104177746522556 , time_score:  500 , memory:  537185\n",
      "Episode:  1180  , Epsilon:  0.01 , Reward -1.57157727080589 , mean_reward:  -20.595246587205843 , time_score:  500 , memory:  539685\n",
      "Episode:  1185  , Epsilon:  0.01 , Reward -17.46480696957894 , mean_reward:  -20.378868049189816 , time_score:  500 , memory:  542185\n",
      "Episode:  1190  , Epsilon:  0.01 , Reward -39.788071880096155 , mean_reward:  -21.33209346432652 , time_score:  500 , memory:  544685\n",
      "Episode:  1195  , Epsilon:  0.01 , Reward 36.17752202784358 , mean_reward:  -20.76974659804148 , time_score:  500 , memory:  546833\n",
      "Episode:  1200  , Epsilon:  0.01 , Reward 27.73469194689343 , mean_reward:  -22.40648047513009 , time_score:  500 , memory:  549333\n",
      "Episode:  1205  , Epsilon:  0.01 , Reward -188.78227279831754 , mean_reward:  -22.500118409691446 , time_score:  177 , memory:  551510\n",
      "Episode:  1210  , Epsilon:  0.01 , Reward 8.289908593498362 , mean_reward:  -21.53175468408275 , time_score:  500 , memory:  554010\n",
      "Episode:  1215  , Epsilon:  0.01 , Reward -5.430270251421413 , mean_reward:  -21.386689126907473 , time_score:  500 , memory:  556135\n",
      "Episode:  1220  , Epsilon:  0.01 , Reward -15.42586732623569 , mean_reward:  -16.079248206795082 , time_score:  148 , memory:  558283\n",
      "Episode:  1225  , Epsilon:  0.01 , Reward 14.660213219605929 , mean_reward:  -18.8959721927876 , time_score:  500 , memory:  560449\n",
      "Episode:  1230  , Epsilon:  0.01 , Reward 57.3473059685611 , mean_reward:  -17.695281959836638 , time_score:  500 , memory:  562603\n",
      "Episode:  1235  , Epsilon:  0.01 , Reward -33.318254642258395 , mean_reward:  -18.864491004385588 , time_score:  88 , memory:  564691\n",
      "Episode:  1240  , Epsilon:  0.01 , Reward 0.2856847514619152 , mean_reward:  -16.749339440253813 , time_score:  500 , memory:  566819\n",
      "Episode:  1245  , Epsilon:  0.01 , Reward -34.1932441575252 , mean_reward:  -10.973069090485264 , time_score:  500 , memory:  569319\n",
      "Episode:  1250  , Epsilon:  0.01 , Reward 17.3792689642376 , mean_reward:  -9.8561324727418 , time_score:  500 , memory:  571504\n",
      "Episode:  1255  , Epsilon:  0.01 , Reward 73.1241734066004 , mean_reward:  -8.110127014753356 , time_score:  500 , memory:  574004\n",
      "Episode:  1260  , Epsilon:  0.01 , Reward 34.78551476577833 , mean_reward:  -7.964829670953651 , time_score:  500 , memory:  576504\n",
      "Episode:  1265  , Epsilon:  0.01 , Reward 15.363706673294935 , mean_reward:  -6.683683234990566 , time_score:  500 , memory:  579004\n",
      "Episode:  1270  , Epsilon:  0.01 , Reward -20.883381613823797 , mean_reward:  -8.666382095048304 , time_score:  500 , memory:  581155\n",
      "Episode:  1275  , Epsilon:  0.01 , Reward -5.907990453921471 , mean_reward:  -9.120350761402277 , time_score:  500 , memory:  583612\n",
      "Episode:  1280  , Epsilon:  0.01 , Reward 55.295515426298735 , mean_reward:  -8.289140231605158 , time_score:  500 , memory:  586112\n",
      "Episode:  1285  , Epsilon:  0.01 , Reward 1.997856638534799 , mean_reward:  -8.22026499309572 , time_score:  500 , memory:  588612\n",
      "Episode:  1290  , Epsilon:  0.01 , Reward -10.160817605089733 , mean_reward:  -7.643347747123147 , time_score:  500 , memory:  591112\n",
      "Episode:  1295  , Epsilon:  0.01 , Reward 37.45397387864263 , mean_reward:  -4.0385989593205975 , time_score:  500 , memory:  593380\n",
      "Episode:  1300  , Epsilon:  0.01 , Reward 95.03817289786993 , mean_reward:  -1.616177017948466 , time_score:  500 , memory:  595880\n",
      "Episode:  1305  , Epsilon:  0.01 , Reward 34.069828796943554 , mean_reward:  -1.8309262750167425 , time_score:  500 , memory:  598097\n",
      "Episode:  1310  , Epsilon:  0.01 , Reward 15.997949046838938 , mean_reward:  -0.3565974847069413 , time_score:  500 , memory:  600597\n",
      "Episode:  1315  , Epsilon:  0.01 , Reward 20.761846260397363 , mean_reward:  0.7496311110427887 , time_score:  500 , memory:  603097\n",
      "Episode:  1320  , Epsilon:  0.01 , Reward -10.148965162875484 , mean_reward:  0.9898384801318909 , time_score:  500 , memory:  605597\n",
      "Episode:  1325  , Epsilon:  0.01 , Reward 40.364638474218445 , mean_reward:  5.144199481793201 , time_score:  500 , memory:  608097\n",
      "Episode:  1330  , Epsilon:  0.01 , Reward 49.41261034269811 , mean_reward:  9.344685767859898 , time_score:  500 , memory:  610597\n",
      "Episode:  1335  , Epsilon:  0.01 , Reward 58.177313376781875 , mean_reward:  11.090458343771258 , time_score:  500 , memory:  613097\n",
      "Episode:  1340  , Epsilon:  0.01 , Reward 44.71184444950214 , mean_reward:  12.617982556552706 , time_score:  500 , memory:  615597\n",
      "Episode:  1345  , Epsilon:  0.01 , Reward -19.508994952626466 , mean_reward:  12.993565223283488 , time_score:  500 , memory:  618097\n",
      "Episode:  1350  , Epsilon:  0.01 , Reward 40.9916415656824 , mean_reward:  16.088117559217483 , time_score:  500 , memory:  620597\n",
      "Episode:  1355  , Epsilon:  0.01 , Reward 35.14115425777638 , mean_reward:  15.27236044730733 , time_score:  151 , memory:  622748\n",
      "Episode:  1360  , Epsilon:  0.01 , Reward 52.357587427697624 , mean_reward:  16.610025537156783 , time_score:  500 , memory:  625248\n",
      "Episode:  1365  , Epsilon:  0.01 , Reward 51.64948871266575 , mean_reward:  19.158148937088797 , time_score:  500 , memory:  627748\n",
      "Episode:  1370  , Epsilon:  0.01 , Reward 15.486901300926869 , mean_reward:  23.34653153068997 , time_score:  500 , memory:  630248\n",
      "Episode:  1375  , Epsilon:  0.01 , Reward -93.59240140362907 , mean_reward:  23.518235009387027 , time_score:  176 , memory:  632111\n",
      "Episode:  1380  , Epsilon:  0.01 , Reward 16.03919024529159 , mean_reward:  22.325853789536392 , time_score:  500 , memory:  634243\n",
      "Episode:  1385  , Epsilon:  0.01 , Reward 47.31456415447476 , mean_reward:  23.20979833527291 , time_score:  500 , memory:  636743\n",
      "Episode:  1390  , Epsilon:  0.01 , Reward 28.674023402683464 , mean_reward:  23.915202803450597 , time_score:  500 , memory:  639243\n",
      "Episode:  1395  , Epsilon:  0.01 , Reward 50.77660586990954 , mean_reward:  24.503138982056033 , time_score:  500 , memory:  641743\n",
      "Episode:  1400  , Epsilon:  0.01 , Reward 57.539743342759074 , mean_reward:  24.108472259853357 , time_score:  500 , memory:  644243\n",
      "Episode:  1405  , Epsilon:  0.01 , Reward 53.496551059021016 , mean_reward:  26.72479798942875 , time_score:  500 , memory:  646743\n",
      "Episode:  1410  , Epsilon:  0.01 , Reward 68.15088583783876 , mean_reward:  27.575371911649878 , time_score:  500 , memory:  649243\n",
      "Episode:  1415  , Epsilon:  0.01 , Reward 18.944893189292824 , mean_reward:  28.472950562788196 , time_score:  500 , memory:  651743\n",
      "Episode:  1420  , Epsilon:  0.01 , Reward 35.48977672608807 , mean_reward:  30.66107986738132 , time_score:  500 , memory:  654243\n",
      "Episode:  1425  , Epsilon:  0.01 , Reward 62.08476527596409 , mean_reward:  30.407457837863536 , time_score:  500 , memory:  656743\n",
      "Episode:  1430  , Epsilon:  0.01 , Reward 14.379660031532515 , mean_reward:  29.587227025581953 , time_score:  500 , memory:  659243\n",
      "Episode:  1435  , Epsilon:  0.01 , Reward 52.681305090042194 , mean_reward:  30.176579807289002 , time_score:  500 , memory:  661743\n",
      "Episode:  1440  , Epsilon:  0.01 , Reward 64.14203988214815 , mean_reward:  31.962421911184247 , time_score:  500 , memory:  664243\n",
      "Episode:  1445  , Epsilon:  0.01 , Reward 14.150997280993852 , mean_reward:  27.970957579724608 , time_score:  500 , memory:  666084\n",
      "Episode:  1450  , Epsilon:  0.01 , Reward 39.159566038806595 , mean_reward:  27.774752951275392 , time_score:  500 , memory:  668166\n",
      "Episode:  1455  , Epsilon:  0.01 , Reward 6.619377638151156 , mean_reward:  28.17968926639683 , time_score:  500 , memory:  670666\n",
      "Episode:  1460  , Epsilon:  0.01 , Reward 65.90930248063397 , mean_reward:  29.255405347825608 , time_score:  500 , memory:  673166\n",
      "Episode:  1465  , Epsilon:  0.01 , Reward 48.78880681434203 , mean_reward:  29.149222842164885 , time_score:  500 , memory:  675666\n",
      "Episode:  1470  , Epsilon:  0.01 , Reward 30.285501634673704 , mean_reward:  29.722356649440215 , time_score:  500 , memory:  678166\n",
      "Episode:  1475  , Epsilon:  0.01 , Reward 20.602437897314573 , mean_reward:  33.42843736025584 , time_score:  500 , memory:  680666\n",
      "Episode:  1480  , Epsilon:  0.01 , Reward 27.285123632143137 , mean_reward:  35.09695398666408 , time_score:  500 , memory:  683166\n",
      "Episode:  1485  , Epsilon:  0.01 , Reward 52.8962135963307 , mean_reward:  36.16152408495172 , time_score:  500 , memory:  685666\n",
      "Episode:  1490  , Epsilon:  0.01 , Reward 29.913198231096903 , mean_reward:  37.28445783880554 , time_score:  500 , memory:  688166\n",
      "Episode:  1495  , Epsilon:  0.01 , Reward 27.345554474077822 , mean_reward:  37.59505650679966 , time_score:  500 , memory:  690666\n",
      "Episode:  1500  , Epsilon:  0.01 , Reward 40.1119882485698 , mean_reward:  37.27746703415757 , time_score:  500 , memory:  693166\n",
      "Episode:  1505  , Epsilon:  0.01 , Reward 34.4094896431603 , mean_reward:  37.452844992339216 , time_score:  500 , memory:  695666\n",
      "Episode:  1510  , Epsilon:  0.01 , Reward 75.4393101603063 , mean_reward:  38.24915122084251 , time_score:  500 , memory:  698166\n",
      "Episode:  1515  , Epsilon:  0.01 , Reward 45.57323524359695 , mean_reward:  38.790275601735 , time_score:  500 , memory:  700666\n",
      "Episode:  1520  , Epsilon:  0.01 , Reward 32.12085772147379 , mean_reward:  39.23876469124617 , time_score:  500 , memory:  703166\n",
      "Episode:  1525  , Epsilon:  0.01 , Reward 11.785238736385082 , mean_reward:  39.29192397447719 , time_score:  500 , memory:  705666\n",
      "Episode:  1530  , Epsilon:  0.01 , Reward -56.098569891597556 , mean_reward:  39.56045399636735 , time_score:  288 , memory:  707954\n",
      "Episode:  1535  , Epsilon:  0.01 , Reward 22.690193813882612 , mean_reward:  38.87392358598065 , time_score:  500 , memory:  710454\n",
      "Episode:  1540  , Epsilon:  0.01 , Reward 66.7332793324549 , mean_reward:  38.81611239751417 , time_score:  500 , memory:  712954\n",
      "Episode:  1545  , Epsilon:  0.01 , Reward 47.251866990880266 , mean_reward:  42.9592841480559 , time_score:  500 , memory:  715454\n",
      "Episode:  1550  , Epsilon:  0.01 , Reward 44.90663653485747 , mean_reward:  43.67932399428476 , time_score:  500 , memory:  717954\n",
      "Episode:  1555  , Epsilon:  0.01 , Reward 32.48239355566071 , mean_reward:  43.80953464135527 , time_score:  500 , memory:  720454\n",
      "Episode:  1560  , Epsilon:  0.01 , Reward 31.153136550062754 , mean_reward:  43.75042450859395 , time_score:  500 , memory:  722954\n",
      "Episode:  1565  , Epsilon:  0.01 , Reward -55.58568865313335 , mean_reward:  43.03705321246887 , time_score:  500 , memory:  725454\n",
      "Episode:  1570  , Epsilon:  0.01 , Reward 13.71677270676033 , mean_reward:  43.31070053773561 , time_score:  500 , memory:  727954\n",
      "Episode:  1575  , Epsilon:  0.01 , Reward 62.210355122424474 , mean_reward:  42.674993301487746 , time_score:  500 , memory:  730454\n",
      "Episode:  1580  , Epsilon:  0.01 , Reward 18.193545781537985 , mean_reward:  41.14347778563533 , time_score:  500 , memory:  732856\n",
      "Episode:  1585  , Epsilon:  0.01 , Reward 28.233701254844185 , mean_reward:  40.51304458824885 , time_score:  500 , memory:  735356\n",
      "Episode:  1590  , Epsilon:  0.01 , Reward 25.94762086377133 , mean_reward:  40.17778006765548 , time_score:  500 , memory:  737856\n",
      "Episode:  1595  , Epsilon:  0.01 , Reward 68.38692400246843 , mean_reward:  40.77844789020752 , time_score:  500 , memory:  740356\n",
      "Episode:  1600  , Epsilon:  0.01 , Reward -108.73100963207877 , mean_reward:  39.43520208516775 , time_score:  427 , memory:  742783\n",
      "Episode:  1605  , Epsilon:  0.01 , Reward 81.37652211681333 , mean_reward:  39.670181254515946 , time_score:  500 , memory:  745283\n",
      "Episode:  1610  , Epsilon:  0.01 , Reward 6.639371854889794 , mean_reward:  38.43751467744319 , time_score:  500 , memory:  747783\n",
      "Episode:  1615  , Epsilon:  0.01 , Reward 45.5506328756223 , mean_reward:  38.03955501386748 , time_score:  500 , memory:  750283\n",
      "Episode:  1620  , Epsilon:  0.01 , Reward 43.41744606998813 , mean_reward:  38.431373391101765 , time_score:  500 , memory:  752783\n",
      "Episode:  1625  , Epsilon:  0.01 , Reward 23.144712148149765 , mean_reward:  38.364107123361684 , time_score:  500 , memory:  755283\n",
      "Episode:  1630  , Epsilon:  0.01 , Reward 15.958233589053096 , mean_reward:  36.45063528238242 , time_score:  500 , memory:  757410\n",
      "Episode:  1635  , Epsilon:  0.01 , Reward 56.81738611487287 , mean_reward:  34.596035993019164 , time_score:  500 , memory:  759587\n",
      "Episode:  1640  , Epsilon:  0.01 , Reward -52.67092100621501 , mean_reward:  33.24040241235243 , time_score:  254 , memory:  761841\n",
      "Episode:  1645  , Epsilon:  0.01 , Reward 72.08964077300328 , mean_reward:  33.41723316466153 , time_score:  500 , memory:  764341\n",
      "Episode:  1650  , Epsilon:  0.01 , Reward 53.92988331832681 , mean_reward:  33.270449216080834 , time_score:  500 , memory:  766841\n",
      "Episode:  1655  , Epsilon:  0.01 , Reward 32.02200876265646 , mean_reward:  33.59596324424642 , time_score:  500 , memory:  769341\n",
      "Episode:  1660  , Epsilon:  0.01 , Reward 51.1143638528963 , mean_reward:  33.38416642108148 , time_score:  500 , memory:  771841\n",
      "Episode:  1665  , Epsilon:  0.01 , Reward 36.716375815468055 , mean_reward:  34.491207307756646 , time_score:  500 , memory:  774341\n",
      "Episode:  1670  , Epsilon:  0.01 , Reward 28.06192929078602 , mean_reward:  34.24892383796302 , time_score:  500 , memory:  776841\n",
      "Episode:  1675  , Epsilon:  0.01 , Reward 50.961619707829584 , mean_reward:  33.91509674509076 , time_score:  500 , memory:  779341\n",
      "Episode:  1680  , Epsilon:  0.01 , Reward 44.9629382349103 , mean_reward:  35.380695536899694 , time_score:  500 , memory:  781841\n",
      "Episode:  1685  , Epsilon:  0.01 , Reward 54.61010732293202 , mean_reward:  33.1287981835193 , time_score:  500 , memory:  783965\n",
      "Episode:  1690  , Epsilon:  0.01 , Reward 55.734372836376394 , mean_reward:  32.60666200584835 , time_score:  500 , memory:  786465\n",
      "Episode:  1695  , Epsilon:  0.01 , Reward 45.109201799045636 , mean_reward:  31.57822919080848 , time_score:  500 , memory:  788965\n",
      "Episode:  1700  , Epsilon:  0.01 , Reward 59.521888134667954 , mean_reward:  32.94012106338325 , time_score:  500 , memory:  791465\n",
      "Episode:  1705  , Epsilon:  0.01 , Reward 37.537631992291935 , mean_reward:  32.136682271129494 , time_score:  500 , memory:  793965\n",
      "Episode:  1710  , Epsilon:  0.01 , Reward 23.738476247645515 , mean_reward:  31.38263515296382 , time_score:  500 , memory:  796465\n",
      "Episode:  1715  , Epsilon:  0.01 , Reward 45.372160115067935 , mean_reward:  31.03662462542115 , time_score:  500 , memory:  798965\n",
      "Episode:  1720  , Epsilon:  0.01 , Reward 44.6168948945038 , mean_reward:  30.224054344342267 , time_score:  500 , memory:  801465\n",
      "Episode:  1725  , Epsilon:  0.01 , Reward 4.934820121722124 , mean_reward:  30.106750155053884 , time_score:  500 , memory:  803965\n",
      "Episode:  1730  , Epsilon:  0.01 , Reward 54.282547378905136 , mean_reward:  32.72393452938618 , time_score:  500 , memory:  806465\n",
      "Episode:  1735  , Epsilon:  0.01 , Reward 49.268002875208126 , mean_reward:  34.69207804000747 , time_score:  500 , memory:  808965\n",
      "Episode:  1740  , Epsilon:  0.01 , Reward 45.5050630957076 , mean_reward:  34.82577656230094 , time_score:  500 , memory:  811465\n",
      "Episode:  1745  , Epsilon:  0.01 , Reward 9.855596739109073 , mean_reward:  34.82687539155275 , time_score:  500 , memory:  813965\n",
      "Episode:  1750  , Epsilon:  0.01 , Reward 61.29508022940871 , mean_reward:  34.018422538486874 , time_score:  500 , memory:  816465\n",
      "Episode:  1755  , Epsilon:  0.01 , Reward 68.16352690105165 , mean_reward:  34.12436906772366 , time_score:  500 , memory:  818965\n",
      "Episode:  1760  , Epsilon:  0.01 , Reward 43.05282141160111 , mean_reward:  33.36538969251294 , time_score:  500 , memory:  821465\n",
      "Episode:  1765  , Epsilon:  0.01 , Reward 0.752026725054195 , mean_reward:  32.590085469196694 , time_score:  500 , memory:  823965\n",
      "Episode:  1770  , Epsilon:  0.01 , Reward 30.74510893157879 , mean_reward:  30.73389846213404 , time_score:  500 , memory:  826390\n",
      "Episode:  1775  , Epsilon:  0.01 , Reward 3.0855444833262737 , mean_reward:  28.991773588477372 , time_score:  500 , memory:  828684\n",
      "Episode:  1780  , Epsilon:  0.01 , Reward 30.285447134545638 , mean_reward:  28.343413124940966 , time_score:  500 , memory:  831184\n",
      "Episode:  1785  , Epsilon:  0.01 , Reward 22.075513148300665 , mean_reward:  30.52963505940625 , time_score:  500 , memory:  833684\n",
      "Episode:  1790  , Epsilon:  0.01 , Reward 11.208367689660676 , mean_reward:  30.661159302003036 , time_score:  500 , memory:  836184\n",
      "Episode:  1795  , Epsilon:  0.01 , Reward 25.673893887766443 , mean_reward:  30.858832375111135 , time_score:  500 , memory:  838684\n",
      "Episode:  1800  , Epsilon:  0.01 , Reward 22.27523344688542 , mean_reward:  30.63891184048777 , time_score:  500 , memory:  841184\n",
      "Episode:  1805  , Epsilon:  0.01 , Reward 70.1371041893288 , mean_reward:  31.0446247695966 , time_score:  500 , memory:  843684\n",
      "Episode:  1810  , Epsilon:  0.01 , Reward 49.69099246918546 , mean_reward:  32.343217134760614 , time_score:  500 , memory:  846184\n",
      "Episode:  1815  , Epsilon:  0.01 , Reward -71.70948176836063 , mean_reward:  30.527856553616335 , time_score:  240 , memory:  848146\n",
      "Episode:  1820  , Epsilon:  0.01 , Reward 57.84882881780527 , mean_reward:  27.542226327442823 , time_score:  500 , memory:  850044\n",
      "Episode:  1825  , Epsilon:  0.01 , Reward 51.249811372850175 , mean_reward:  26.928356053956236 , time_score:  500 , memory:  852544\n",
      "Episode:  1830  , Epsilon:  0.01 , Reward 10.783846543254304 , mean_reward:  26.60848464857449 , time_score:  500 , memory:  855044\n",
      "Episode:  1835  , Epsilon:  0.01 , Reward 44.0216130236399 , mean_reward:  26.183372374882126 , time_score:  500 , memory:  857334\n",
      "Episode:  1840  , Epsilon:  0.01 , Reward 44.410278759210975 , mean_reward:  25.944165237692154 , time_score:  500 , memory:  859834\n",
      "Episode:  1845  , Epsilon:  0.01 , Reward 90.63576257809085 , mean_reward:  25.236147479518923 , time_score:  500 , memory:  862299\n",
      "Episode:  1850  , Epsilon:  0.01 , Reward 8.605655976001488 , mean_reward:  21.606595327916363 , time_score:  500 , memory:  864164\n",
      "Episode:  1855  , Epsilon:  0.01 , Reward -1.6606033499994945 , mean_reward:  20.145212899443095 , time_score:  500 , memory:  866664\n",
      "Episode:  1860  , Epsilon:  0.01 , Reward -125.47935133251683 , mean_reward:  18.478798624502907 , time_score:  195 , memory:  868859\n",
      "Episode:  1865  , Epsilon:  0.01 , Reward 23.528081882766156 , mean_reward:  17.720598720701847 , time_score:  500 , memory:  871359\n",
      "Episode:  1870  , Epsilon:  0.01 , Reward 37.36327539321228 , mean_reward:  19.56393100360131 , time_score:  500 , memory:  873859\n",
      "Episode:  1875  , Epsilon:  0.01 , Reward -11.185333448059652 , mean_reward:  20.288987461925526 , time_score:  500 , memory:  876359\n",
      "Episode:  1880  , Epsilon:  0.01 , Reward 87.9357538334902 , mean_reward:  21.850165298015963 , time_score:  500 , memory:  878859\n",
      "Episode:  1885  , Epsilon:  0.01 , Reward 13.776549892256103 , mean_reward:  20.606900532543264 , time_score:  500 , memory:  881359\n",
      "Episode:  1890  , Epsilon:  0.01 , Reward 55.4193963642276 , mean_reward:  21.43723905984489 , time_score:  500 , memory:  883859\n",
      "Episode:  1895  , Epsilon:  0.01 , Reward 45.56114402987553 , mean_reward:  21.436662564536114 , time_score:  500 , memory:  886359\n",
      "Episode:  1900  , Epsilon:  0.01 , Reward 32.46264715675205 , mean_reward:  20.997410349177848 , time_score:  500 , memory:  888859\n",
      "Episode:  1905  , Epsilon:  0.01 , Reward 37.68134797573119 , mean_reward:  20.655208958571894 , time_score:  500 , memory:  891359\n",
      "Episode:  1910  , Epsilon:  0.01 , Reward 25.1742859589856 , mean_reward:  20.98610902461657 , time_score:  500 , memory:  893859\n",
      "Episode:  1915  , Epsilon:  0.01 , Reward 24.002403712408906 , mean_reward:  21.641392099513787 , time_score:  500 , memory:  896359\n",
      "Episode:  1920  , Epsilon:  0.01 , Reward 14.842900130935647 , mean_reward:  24.25680489603549 , time_score:  500 , memory:  898859\n",
      "Episode:  1925  , Epsilon:  0.01 , Reward 50.79924410413413 , mean_reward:  25.040670615728377 , time_score:  500 , memory:  901359\n",
      "Episode:  1930  , Epsilon:  0.01 , Reward 30.295394303769825 , mean_reward:  24.3164993847613 , time_score:  500 , memory:  903859\n",
      "Episode:  1935  , Epsilon:  0.01 , Reward 5.30300331583317 , mean_reward:  24.781553503253026 , time_score:  500 , memory:  906359\n",
      "Episode:  1940  , Epsilon:  0.01 , Reward 17.96280085110583 , mean_reward:  25.116025141341442 , time_score:  500 , memory:  908859\n",
      "Episode:  1945  , Epsilon:  0.01 , Reward 2.3961000903950507 , mean_reward:  26.095222729532253 , time_score:  500 , memory:  911359\n",
      "Episode:  1950  , Epsilon:  0.01 , Reward 30.666680696549125 , mean_reward:  30.022216879331637 , time_score:  500 , memory:  913859\n",
      "Episode:  1955  , Epsilon:  0.01 , Reward 25.098418875868436 , mean_reward:  30.247116616720618 , time_score:  500 , memory:  916359\n",
      "Episode:  1960  , Epsilon:  0.01 , Reward 10.905411593264088 , mean_reward:  30.629719583419067 , time_score:  500 , memory:  918859\n",
      "Episode:  1965  , Epsilon:  0.01 , Reward 29.256689403394045 , mean_reward:  30.802447795642234 , time_score:  500 , memory:  921359\n",
      "Episode:  1970  , Epsilon:  0.01 , Reward 24.478545668895187 , mean_reward:  29.57663355802913 , time_score:  500 , memory:  923859\n",
      "Episode:  1975  , Epsilon:  0.01 , Reward 74.15481969828403 , mean_reward:  31.24296932731086 , time_score:  500 , memory:  926359\n",
      "Episode:  1980  , Epsilon:  0.01 , Reward 26.97584572576504 , mean_reward:  30.20404642538296 , time_score:  500 , memory:  928859\n",
      "Episode:  1985  , Epsilon:  0.01 , Reward 30.51694256654477 , mean_reward:  31.139944904824286 , time_score:  500 , memory:  931359\n",
      "Episode:  1990  , Epsilon:  0.01 , Reward 44.70765016971514 , mean_reward:  30.334150313805775 , time_score:  500 , memory:  933859\n",
      "Episode:  1995  , Epsilon:  0.01 , Reward -18.33346428033846 , mean_reward:  29.053765518481878 , time_score:  500 , memory:  936359\n"
     ]
    }
   ],
   "source": [
    "game = \"LunarLander-v2\"\n",
    "dqn = DQN(game, retrain = False, epsilon=0.01 , epsilon_decay = 0.01, epsilon_min = 0.01, batch_size = 64, discount_factor=0.99, episodes=2000, alpha = 0.001, lr=0.0005)\n",
    "df = dqn.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8zEK6_8NkZvY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:green'\n",
    "ax1.set_xlabel('Episodes')\n",
    "ax1.set_ylabel('Reward')\n",
    "ax1.plot(df.iloc[:,0], df.iloc[:,2:3], color=color)\n",
    "ax1.plot(df.iloc[:,0], df.iloc[:,3:4], color='red')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Epsilon')  # we already handled the x-label with ax1\n",
    "ax2.plot(df.iloc[:,0], df.iloc[:,1:2], color=color)\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzXeEPyZkZx5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmu7jobCkZ0S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LctZX16UkZ2z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oUZZ81CkZ5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LigtDnbikZ7h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pic26PzvkZ-I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SM06jVdTkaA0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb-td7BDkaDf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGjInw1qkaF_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8MT-kCZkaIY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHHXj0aMkaLE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3-NkHivkaNq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyOQX7wxBm0680LypbxNFGpd",
   "collapsed_sections": [],
   "mount_file_id": "1muIbyjnAsjYuWdNUWjqeuQv9cv8Grz2U",
   "name": "DQN_0.995_0.005_0.0005.ipynb",
   "provenance": [
    {
     "file_id": "1lqAUGuT7CsohqVFy4vwS8YzO3YFUgWfp",
     "timestamp": 1624337011710
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
